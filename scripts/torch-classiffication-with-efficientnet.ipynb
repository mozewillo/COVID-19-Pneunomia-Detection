{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook's content\n\n1. Getting ready (a.k.a. loading data and packages)\n2. Creating dataset&dataloader objects\n3. Creating neural network model\n4. Training model\n\n# Getting ready","metadata":{}},{"cell_type":"code","source":"%%bash\nconda install -c conda-forge timm -y\nconda install -c conda-forge gdcm -y\npip install --upgrade torchmetrics","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom skimage import exposure, io\nimport time\nimport timm\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, F1, MatthewsCorrcoef\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')\ntrain_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\ntrain_study.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_study.rename(columns={'Negative for Pneumonia': '0','Typical Appearance': '1',\"Indeterminate Appearance\": '2',\n                   \"Atypical Appearance\": \"3\"}, inplace=True)\ntrain_study.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = []\ndef get_label(row):\n    for c in train_study.columns:\n        if row[c] == 1:\n            labels.append(int(c))\n            \ntrain_study.apply(get_label, axis=1)\ntrain_study.drop(columns=['0', '1','2', '3'], inplace=True)\ntrain_study['label'] = labels\ntrain_study.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def get_img(path):\n    im = cv2.imread(path)\n    img = img[:, :, ::-1]\n    img = exposure.equalize_hist(img)\n    return img.astype(np.float32)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovLungDataset(Dataset):\n    def __init__(self, train_study, data_root, transforms=None, output_label=True, one_hot_label=False):\n        super().__init__()\n        \n        self.df = train_study.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.labels = self.df['label'].values\n            \n            if one_hot_label is True:\n                self.labels = np.eye(self.df['label'].max() + 1)[self.labels]\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        # get labels\n        if self.output_label:\n            target = self.labels[index]\n        img = get_img(os.path.join(self.data_root, f'{self.df.loc[index][\"id\"]}.png'))\n    \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n                \n        if self.output_label == True:\n            return img, target\n        else:\n            return img","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader with data augmentation","metadata":{}},{"cell_type":"code","source":"from albumentations import (\n    CoarseDropout, CenterCrop, Compose,\n    Cutout, HorizontalFlip, HueSaturationValue,\n    Normalize, RandomBrightnessContrast, RandomResizedCrop,\n    Resize, ShiftScaleRotate, Transopose,\n    VerticalFlip,\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n  \n        \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(df, trn_idx, val_idx, data_root='../input/siimcovid19-512-img-png-600-study-png/study'):\n    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CovLungDataset(train_, data_root, transforms=get_train_transforms(), output_label=True, one_hot_label=False)\n    # validate on training data\n    valid_ds = CovLungDataset(train_, data_root, transforms=get_valid_transforms(), output_label=True)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_ds,\n        batch_size=CFG['train_bs'],\n        num_workers=CFG['num_workers'],\n        pin_memory=False,\n        drop_last=False,\n        shuffle=True,        \n    )\n    \n    val_loader = torch.utils.data.DataLoader(\n        valid_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n    return train_loader, val_loader","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural network","metadata":{}},{"cell_type":"code","source":"class CovClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def PlotLossFun(epoch, Cur_List, IFTRAIN='TRAIN'):\n    x = range(len(Cur_List))\n    y = Cur_List\n    \n    IFTRAIN = IFTRAIN\n    EPOCHNUM = str(epoch)\n    \n    plt.plot(x,y)\n    plt.xlabel(f'EpochNum:{EPOCHNUM}')\n    plt.ylabel(f'{IFTRAIN}cur')\n    \n    plt.savefig(f\"{IFTRAIN}_epoch{EPOCHNUM}_cur.jpg\")\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):   \n    model.train()\n    Temp_Loss_List = []\n\n    t = time.time()\n    running_loss = None\n\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    \n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = image_labels.to(device).long()\n\n        with autocast():\n            image_preds = model(imgs)\n\n            loss = loss_fn(image_preds, image_labels)\n            \n            scaler.scale(loss).backward()\n\n            if running_loss is None:\n                running_loss = loss.item()\n            else:\n                running_loss = running_loss * .99 + loss.item() * .01\n\n            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n                \n                if scheduler is not None and schd_batch_update:\n                    scheduler.step()\n\n            description = f'epoch {epoch} loss: {running_loss:.4f}'\n            Temp_Loss_List.append(running_loss)\n            pbar.set_description(description)\n    \n    \n    Train_Loss_List.append(np.mean(Temp_Loss_List))\n    if epoch == CFG['epochs'] - 1:\n        PlotLossFun(epoch, Train_Loss_List,IFTRAIN='TRAIN')            \n    if scheduler is not None and not schd_batch_update:\n        scheduler.step()\n    return Train_Loss_List\n        \ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n    acc = Accuracy(num_classes=CFG['n_classes'], average='weighted').to(device)\n    f1 = F1(num_classes=CFG['n_classes']).to(device)\n    mcmc = MatthewsCorrcoef(num_classes=CFG['n_classes']).to(device)\n    \n    model.eval()\n\n    t = time.time()\n    loss_sum = 0\n    sample_num = 0\n    image_preds_all = []\n    image_targets_all = []\n    \n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = image_labels.to(device).long()\n        \n        image_preds = model(imgs)\n        image_preds_all += torch.topk(image_preds, k=1)[1]\n        image_targets_all += image_labels\n        \n        loss = loss_fn(image_preds, image_labels)\n        \n        loss_sum += loss.item() * image_labels.shape[0]\n        sample_num += image_labels.shape[0]  \n\n        description = f'epoch {epoch} loss: {loss_sum / sample_num:.4f}'\n        pbar.set_description(description)\n    \n    image_preds_all = torch.cat(image_preds_all).to(device)\n    image_targets_all = torch.stack(image_targets_all).to(device)\n    acc_ = acc(image_preds_all, image_targets_all)\n    f1_ = f1(image_preds_all, image_targets_all)\n    mcmc_ = mcmc(image_preds_all, image_targets_all)\n    \n    print(f'---- Performance ----\\nweighted acc: {acc_:.4f}, f1: {f1_:.4f}, mcmc: {mcmc_:.4f}')\n    \n    Val_Acc_List.append(acc(image_preds_all, image_targets_all))\n    if epoch == CFG['epochs'] - 1:\n        PlotLossFun(epoch, Val_Acc_List, IFTRAIN='VAL') \n    \n    if scheduler is not None:\n        if schd_loss_update:\n            scheduler.step(loss_sum / sample_num)\n        else:\n            scheduler.step()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"CFG = {\n    'seed': 256,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 30,\n    'train_bs': 16,\n    'valid_bs': 32,\n    'T_0': 10,\n    'lr': 1e-4,\n    'min_lr': 1e-6,\n    'weight_decay': 1e-6,\n    'num_workers': 4,\n    # support to do batch accumulation for backprop with effectively larger batch size\n    'accum_iter': 2,\n    'verbose_step': 1,\n    'device': 'cuda:0'\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for training only, need nightly build pytorch\nseed_everything(CFG['seed'])\n\ntrn_idx, val_idx = next(iter(StratifiedShuffleSplit(n_splits=1, random_state=CFG['seed']).split(\n    np.arange(train_study.shape[0]), train_study.label.values\n)))\n\n\nprint(len(trn_idx), len(val_idx))\ntrain_loader, val_loader = prepare_dataloader(train_study, trn_idx, val_idx, \n                                              data_root='../input/siimcovid19-512-img-png-600-study-png/study')\ndevice = torch.device(CFG['device'])\nmodel = CovClassifier(CFG['model_arch'], train_study.label.nunique(), pretrained=True).to(device)\nscaler = GradScaler()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n\nloss_tr = nn.CrossEntropyLoss().to(device)\nloss_fn = nn.CrossEntropyLoss().to(device)\n\nglobal Train_Loss_List, Val_Acc_List\nTrain_Loss_List = []\nVal_Acc_List = []\n\nfor epoch in range(CFG['epochs']):\n\n    train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=True)\n\n    with torch.no_grad():\n        valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n\n    if epoch%10 == 0:\n        torch.save(model.model.state_dict(), f'efficient_net_{epoch}')\n\ntorch.save(model.model.state_dict(), f'efficient_net_{epoch}')\ndel model, optimizer, train_loader, val_loader, scaler, scheduler\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}